{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Trading with Machine Learning Regression - Part - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we have covered how to import data to create indicators. We defined and independent variables for linear regression. \n",
    "\n",
    "In this notebook, you will learn the machine learning regression technique. We will implement a linear regression model on Gold ETF that will predict the Day's High and Day's Low given its Day's Open, High, Low and Other defined indicators. The key steps are:\n",
    "1. Import the Data\n",
    "2. Preprocess the Data\n",
    "3. Grid Search Cross-Validation\n",
    "4. Split Train and Test Data\n",
    "5. Predict the High and-Low Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Machine Learning libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Plotting \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# To ignore unwanted warnings\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data\n",
    "The input data is stored in `input_parameters.csv`, which we will import here as `gold_prices` to make prediction using Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_15</th>\n",
       "      <th>S_60</th>\n",
       "      <th>Corr</th>\n",
       "      <th>Std_U</th>\n",
       "      <th>Std_D</th>\n",
       "      <th>OD</th>\n",
       "      <th>OL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-15</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.750000</td>\n",
       "      <td>130.509995</td>\n",
       "      <td>131.309998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.490005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-16</th>\n",
       "      <td>134.899994</td>\n",
       "      <td>135.110001</td>\n",
       "      <td>131.759995</td>\n",
       "      <td>132.800003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210007</td>\n",
       "      <td>3.139999</td>\n",
       "      <td>-1.100006</td>\n",
       "      <td>3.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-17</th>\n",
       "      <td>133.809998</td>\n",
       "      <td>134.949997</td>\n",
       "      <td>132.320007</td>\n",
       "      <td>132.869995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.139999</td>\n",
       "      <td>1.489991</td>\n",
       "      <td>-1.089996</td>\n",
       "      <td>1.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-18</th>\n",
       "      <td>134.119995</td>\n",
       "      <td>135.309998</td>\n",
       "      <td>133.619995</td>\n",
       "      <td>134.300003</td>\n",
       "      <td>132.326665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.190003</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.309997</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-19</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>136.020004</td>\n",
       "      <td>134.600006</td>\n",
       "      <td>135.470001</td>\n",
       "      <td>133.323334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>1.399994</td>\n",
       "      <td>1.880005</td>\n",
       "      <td>1.699997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close         S_3  S_15  \\\n",
       "Date                                                                           \n",
       "2013-04-15  136.000000  136.750000  130.509995  131.309998         NaN   NaN   \n",
       "2013-04-16  134.899994  135.110001  131.759995  132.800003         NaN   NaN   \n",
       "2013-04-17  133.809998  134.949997  132.320007  132.869995         NaN   NaN   \n",
       "2013-04-18  134.119995  135.309998  133.619995  134.300003  132.326665   NaN   \n",
       "2013-04-19  136.000000  136.020004  134.600006  135.470001  133.323334   NaN   \n",
       "\n",
       "            S_60  Corr     Std_U     Std_D        OD        OL  \n",
       "Date                                                            \n",
       "2013-04-15   NaN   NaN  0.750000  5.490005       NaN       NaN  \n",
       "2013-04-16   NaN   NaN  0.210007  3.139999 -1.100006  3.589996  \n",
       "2013-04-17   NaN   NaN  1.139999  1.489991 -1.089996  1.009995  \n",
       "2013-04-18   NaN   NaN  1.190003  0.500000  0.309997  1.250000  \n",
       "2013-04-19   NaN   NaN  0.020004  1.399994  1.880005  1.699997  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "gold_prices = pd.read_csv('data/input_parameters.csv', index_col='Date')\n",
    "\n",
    "# Printing the data\n",
    "gold_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for NaN values\n",
    "Here we will for NaN values, then we will drop all the rows having NaN values using `dropna` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      0\n",
       "High      0\n",
       "Low       0\n",
       "Close     0\n",
       "S_3       3\n",
       "S_15     15\n",
       "S_60     60\n",
       "Corr     13\n",
       "Std_U     0\n",
       "Std_D     0\n",
       "OD        1\n",
       "OL        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_prices.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60 NaN values is `S_60`, 15 NaN in `S_15`, 13 NaN values in `S_13` and 3 NaN values in `S_3` etc. Now we will simply drop all the NaN values using `dropna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open     0\n",
       "High     0\n",
       "Low      0\n",
       "Close    0\n",
       "S_3      0\n",
       "S_15     0\n",
       "S_60     0\n",
       "Corr     0\n",
       "Std_U    0\n",
       "Std_D    0\n",
       "OD       0\n",
       "OL       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all the NaN values\n",
    "gold_prices.dropna(inplace=True)\n",
    "\n",
    "# Checking for NaN values\n",
    "gold_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataframe `gold_prices` is free from NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables\n",
    "X = gold_prices[['Open', 'S_3','S_15','S_60','OD','OL', 'Corr']]\n",
    "\n",
    "# Dependent variables for upward deviation\n",
    "yU = gold_prices['Std_U']\n",
    "\n",
    "# Dependent variable for downward deviation\n",
    "yD = gold_prices['Std_D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Feeding the model with preprocessed sata in a machine learning model is essential. Raw data contains many errors, and using such data will result in inconsistent and erroneous results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling\n",
    "Suppose a feature has a variance of an order of magnitude larger than the other features. In that case, it might dominate the objective function and make the estimator unable to learn from other features correctly. To achieve tis, we call the Standard Scaler function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "Linear regression uses independent variables to predict a dependent variable using Linear equation. Here we use X as independent and `yU` and `yD` as the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "We define a list containing tuples that specify various machine learning tasks given in the order of execution.\n",
    "\n",
    "Specify in the steps a list (name, transform) tuples. The 'name' is the variable name given to the task, and the 'transform' is the function used to perform the task. Then, sequentially apply a list of transforms specified in steps using the pipeline.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "    steps = [(name_1, transform_1), (name_2, tranform_2), ...., (name_n, transform_n)]\n",
    "    Pipeline(steps)\n",
    "\n",
    "We are using the following two steps in our pipeline,\n",
    "\n",
    "1. Scaling the data\n",
    "2. Fitting the data using the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we put scaling and then linear regression in the pipeline\n",
    "steps = [('scaler', StandardScaler()), ('linear', LinearRegression())]\n",
    "\n",
    "# Defining pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "There are some parameters that the model itself cannot estimate. But we still need to account for them as they play a crucial role in increasing the performance of the system. Such parameters are called hyperparameters. We used intercept but you can add more hyperparameters to tune this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using intercept as hyperparameter\n",
    "parameters = {'linear__fit_intercept': [0,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross-Validation\n",
    "Cross-validation indicates the model's performance in a practical situation. It is used to tackle the overfitting of the model. We will use the `GridSearchCV` function, an inbuilt function for cross-validation\n",
    "\n",
    "We have set `cv=5` which implies that the grid search will consider five rounds of cross-validation for averaging the performance results. We are using `GridSearchCV` instead of `RandomSearchCV` due to fewer features. `TimeSeriesSplit` splits training data into multiple segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TimeSeriesSplit for cross validation\n",
    "my_cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Defining reg as variable for GridSearch function containing pipeline, hyperparameters, and time series split\n",
    "reg = GridSearchCV(pipeline, parameters, cv=my_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
